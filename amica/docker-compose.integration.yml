version: '3.8'

# Integration Testing Docker Compose
# References container configurations from ./containers/
# For integration tests only

services:
  # OpenAI-compatible mock server
  openai-mock:
    build: ./containers/openai-compatible
    container_name: amica-openai-mock
    ports:
      - "8083:8080"
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8080/health"]
      interval: 5s
      timeout: 3s
      retries: 3

  # Ollama - Local LLM inference
  ollama:
    image: ollama/ollama:latest
    container_name: amica-ollama
    ports:
      - "11434:11434"
    volumes:
      - ollama-data:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/api/tags"]
      interval: 10s
      timeout: 5s
      retries: 5

  # Whisper - Speech-to-text
  whisper:
    image: onerahmet/openai-whisper-asr-webservice:latest
    container_name: amica-whisper
    ports:
      - "9000:9000"
    environment:
      - ASR_MODEL=base
      - ASR_ENGINE=faster_whisper
    volumes:
      - whisper-models:/root/.cache/whisper
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 30s

  # Piper TTS
  piper:
    image: rhasspy/wyoming-piper:latest
    container_name: amica-piper
    ports:
      - "10200:10200"
    volumes:
      - piper-data:/data
    command: ["--voice", "en_US-lessac-medium"]
    healthcheck:
      test: ["CMD-SHELL", "echo 'test' | nc -z localhost 10200 || exit 1"]
      interval: 10s
      timeout: 5s
      retries: 5
      start_period: 20s

volumes:
  ollama-data:
  whisper-models:
  piper-data:

networks:
  default:
    name: amica-integration
